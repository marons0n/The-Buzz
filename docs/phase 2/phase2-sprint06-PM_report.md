# Phase 2 Sprint 8 \- PM Report Template

Use this form to provide your project manager report for Phase 2 Sprint 8\.

## Instructions

Be as thorough and complete as possible, while being brief/concise. Please give detailed answers.

Submit one report per team. This should be submitted by the designated PM, except in approved circumstances. The report should be created as a markdown file (and converted to pdf if required).

In addition to uploading to coursesite, version control this in the `master` branch under the `docs` folder.

## Team Information \[10 points total\]

### Team Information:

* Number: 23  
* Name: Function Junction  
* Mentor: \<Maya Itty, [mni226@lehigh.edu](mailto:mni226@lehigh.edu)\>  
* Weekly live & synchronous meeting:  
  * without mentor: 10/10 5pm-6pm, 10/15 

### Team Roles:

* Project Manager: \<Warren Noubi, [wdn225@lehigh.edu](mailto:uid@lehigh.edu)\>
  * Has this changed from last week (if so, why)?  
  * Yes, New sprint  
* Backend developer: <Lily Fandre, [lmf226@lehigh.edu](mailto:lmf226@lehigh.edu)\>
* Admin developer:   \<Stefania Dzhaman [sad823@lehigh.edu](mailto:uid@lehigh.edu)\>
* Mobile developer:     \<Matthew Aronson, [maa362@lehigh.edu](mailto:maa362@lehigh.edu)\>  
* Web developer: \<Andre Escobedo, [aee225@lehigh.edu](mailto:uid@lehigh.edu)\>
### Essential links for this project:

* Team's Dokku URL(s)  
  * [https://team-untitled-23.dokku.cse.lehigh.edu/](https://team-x.dokku.cse.lehigh.edu/)  
* Team's software repo (bitbucket)  
  * [https://bitbucket.org/sml3/cse216\_fa24\_team\_23](https://bitbucket.org/sml3/cse216_fa24_team_23)  
* Team's Jira board  
  * [https://cse216-fa24-team-23.atlassian.net](https://cse216-fa24-team-23.atlassian.net)

## General questions \[15 points total\]

1. Did the PM for this week submit this report (If not, why not?)?  
   Yes  
     
2. Has the team been gathering for a weekly, in-person meeting(s)? If not, why not?  
   Yes   
     
3. Summarize how well the team met the requirements of this sprint.  
     
   * Comment both on the sprint as a whole, as well as on the the individual members efforts.  
   * Comment both on the app design as a whole, as well as on the design and implementation of individual components.  
   * As PM, you should request each non-PM member to evaluate and report on how well requirements related to their efforts were met in this sprint.  
     * For example, how well did each member balance and make best use of their time across their individual work, as tutorial and group-work (including class time, if relevant).

   The team worked mainly separately to complete this week's sprint but we met multiple times to go through the requirements and help each other with our portions. We then all got together to finalize our design and film a video.

   

4. Report on each member's progress (sprint and phase activity completion) – "what is the status?"  
     
   * If incomplete, what challenges are being overcome, how are they being overcome, and by when will the team member be able to finish?  
   * If complete, how do you know everyone completed the work, and at a satisfactory level?

   Each member has completed the activities for this week's sprint. We checked over and finalized everyone's work in person.

   

5. Summary of "code review" during which each team member discussed and showed their progress – "how did you confirm the status?"  
     
   * More details will follow on code reviews.  
   * For now, report out on **when** (once? multiple times?) and **how** (in person? zoom? Watching a recording?) each member showed *and discussed* their progress.  
     * Was this done individually with the PM, or together as a team?  
     * Did you watch each other’s videos? Did you each look at each others’ jira boards and git commit history?  
     * Did you notify each other via slack as you completed each tutorial?  
     * Were these reviews scheduled, or "on-demand" / as completed?

   We met on zoom to get verbal updates from each member on the status of their tasks, and confirmed visually in person as well as had check-ins on Slack if there were any problems. I went over the code with each person and checked it on their branches to make sure it was done and working.

   

6. What did you do to encourage the team to be working on phase activities "sooner rather than later"?  
   Daily check-ins with the team and encouraged them to reach out with any problems. Made sure the backend was up and running before anything else.  
     
7. What did you do to encourage the team to help one another?  
   Met often, checked in often and made sure everyone was where they needed to be.  
     
8. How well is the team communicating?  
     
   * What is the nature of the conversations? Is it all business, or are you getting to know each other better in small and various ways?  
   * Has one or more team members been communicating infrequently, only after a long delay, or in a non-transparent way?  
     * If so, what did you and/or the team do about this? How was this handled?  
     * What was the reaction?  
     * Has communication improved?

   The team is communicating decently well. It is often hard to find time and get responses about when everyone can meet but generally people respond pretty quickly on Slack. he conversations tend to be mostly business and check-ins but the team overall has been getting along very well. 

   

9. Discuss expectations the team has set for one another, if any. Please highlight any changes from last week.  
     
   * Some examples you may have reached consensus on are:  
     * acceptable and unacceptable behaviors,  
     * frequency of asynchronous communication (e.g. slack),  
     * regularity of "live" check-ins (in person, or on e.g. zoom),  
     * turn-taking or "stage sharing" during live meetings,  
     * safe ways to express discomfort or disagreement should emotions or tensions flare.

   Our expectations for our team are the same as weeks prior, open and honest communication and to not be afraid to voice an opinion, setting and meeting realistic deadlines, using recitation time for work or if having any issues but expected to have most of the weeks work done by recitation time, pushing regularly to git so team members can observe and reference other's work.

   

10. If anything was especially challenging or unclear, please make sure this is \[1\] itemized, \[2\] briefly described, \[3\] its status reported (resolved or unresolved), and \[4\] includes critical steps taken to find resolution.  
      
    * Challenge: N/A 
      * Status: (resolved or unresolved)  
      * Description:  
      * Critical steps taken to find resolution:

## Project Management
Self-evaluation of PM performance

0. When did your team meet with your mentor, and for how long?

   We met with the mentor on Tuesday , for 30 minuntes

1. Describe your use of Jira.  Did you have too much detail?  Too little?  Just enough? Did you implement policies around its use (if so, what were they?)?
   Our Jira board maintained balanced detail with the following policies:

Epics created for major features (OAuth, Voting, Comments, Profiles)
Stories broken down into 2-4 hour tasks
Required fields: description, acceptance criteria, story points
Daily status updates mandatory
Labels for frontend/backend/mobile components

2. How did you conduct team meetings?  How did your team interact outside of these meetings?
Meetings on sunday and Thursday 
Outside Communication

Active Slack channels for component-specific discussions
Pair programming sessions scheduled as needed
Async code reviews through Bitbucket
Documentation updates in shared Google Docs
3. What techniques (daily check-ins/scrums, team programming, timelines, Jira use, slack use, group design exercises) did you use to mitigate risk? Highlight any changes from last week.

Daily Slack check-ins for early problem identification
Pair programming for complex features
Regular code reviews to maintain quality
Technical spike sessions for new technologies
Clear documentation requirements
Regular commits and pull requests

4. Describe any difficulties you faced in managing the interactions among your teammates. Were there any team issues that arose? If not, what do you believe is keeping thins so constructive?
Successes

Open communication culture
Proactive problem-solving
Strong knowledge sharing
Respectful code reviews

Contributing Factors

Clear role definitions
Regular check-ins
Transparent decision-making
Collaborative problem-solving approach
5. What is your biggest concern as you think ahead to the next sprint?

Primary concerns for Sprint 9:

Integration complexity between components
Security implementation for OAuth
Meeting performance requirements
Testing coverage across all features
Timeline for user acceptance testing
6. Describe the most significant obstacle or difficulty your team faced.

Major challenges faced:

OAuth Implementation Complexity

Resolution: Created detailed technical documentation
Organized knowledge sharing sessions
Established clear integration points


Cross-platform Authentication

Resolution: Regular sync meetings between web and mobile teams
Created shared authentication utilities
Implemented consistent error handling

7. What might you suggest the team or the next PM "start", "stop", or "continue" doing in the next sprint?
    Start

Weekly technical deep-dive sessions
Cross-component integration testing
Documentation reviews
Security audits

Stop

Delayed task starts
Isolated component development
Late pull request submissions
Postponing testing

Continue

Daily check-ins
Pair programming sessions
Thorough code reviews
Knowledge sharing

8. How well did you estimate time during the early part of the sprint? How did your time estimates change as the sprint progressed?
Initial Estimates

OAuth Implementation: 3 days (Actual: 5 days)
Database Schema: 2 days (Actual: 2 days)
Frontend Integration: 4 days (Actual: 3 days)
Testing: 2 days (Ongoing)

Adjustments Made

Added buffer time for integration
Increased estimation for security implementation
Allocated more time for testing
Added contingency for unexpected issues

9. What aspects of the project would cause concern for your customer right now, if any?    
Current Risks

Security Implementation

Mitigation: External security review
Regular penetration testing
Comprehensive documentation


Performance

Mitigation: Load testing implementation
Performance monitoring setup
Optimization planning


User Experience

Mitigation: Early user testing
Feedback collection plan
Regular UX reviews



Action Items

Security

Complete security audit
Document security measures
Implement monitoring


Performance

Establish performance baselines
Implement monitoring
Create optimization plan


User Experience

Conduct usability testing
Gather user feedback
Implement improvements
